---
layout: about
title: about
permalink: /
subtitle: ML @ Adobe | AI/CS PhD @ Oregon State University

profile:
  align: right
  image: me.jpeg
  image_circular: true
  more_info: >
news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

# About

I’m an ML Engineer/Researcher at **Adobe**, working on model **evaluation**, **safety/harm mitigation**, and **intelligent prompting** for **Firefly**. I helped launch the newest generation of Firefly’s image generation and editing models, with a focus on **reliable behavior** and **user-intent following** in creative workflows. I’m on [Oliver Brdiczka](https://www.cc.gatech.edu/people/oliver-brdiczka)’s team in Adobe’s Applied Science & Machine Learning org, work closely with the Creative Intelligence Lab in Adobe Research, and collaborate with Legal and Applied Ethics teams to build end-to-end, responsible solutions.

Previously, I completed my PhD at the intersection of multimodal AI, human–computer interaction, and fairness in the [Artificial Intelligence](https://eecs.oregonstate.edu/ai-degree-program) and [Computer Science](https://eecs.oregonstate.edu/academics/graduate/cs) programs at Oregon State University, advised by [Stefan Lee](https://web.engr.oregonstate.edu/~leestef/) (and [Minsuk Kahng](https://minsuk.com/) prior to his move to Google).

My work evaluates large-scale vision–language models (e.g., CLIP, ViLBERT, LLaVA, diffusion-based TTI), audits the real-world steps needed to ship them responsibly, and designs mitigations that promote **reliable, human-centered** outcomes across the model lifecycle—from data and training to deployment and monitoring.

Beyond research and engineering, I co-led OSU’s [AI Graduate Student Association](https://www.aigsa.club/) and helped start the [AI Application Support Program](https://www.aigsa.club/aiasp/) to mentor applicants—especially those from underrepresented backgrounds.

**Current focus:** Responsible generative AI; evaluation at scale; reliability & user-intent alignment; dataset/process transparency; practical tooling that meets industry constraints.

---

### Public Speaking & Media

I’m passionate about public speaking and outreach (including invited talks at places like **Apple**, **Google**, and **Sony**). A few highlights include:

- *“Oregon and Washington graduate students tackle problem of bias in AI”* — [OPB, Think Out Loud](https://www.opb.org/article/2024/07/19/think-out-loud-oregon-washington-graduate-students-tackle-problem-bias-ai/)
- *“OSU researcher works to screen the bias out of AI”* — [Jefferson Public Radio (NPR)](https://www.ijpr.org/show/the-jefferson-exchange/2024-07-12/mon-9-am-osu-researcher-works-to-screen-the-bias-out-of-ai)
- *“Adobe Researchers Develop New Training Technique to Make AI Less Socially Biased”* — [TechTimes](https://www.techtimes.com/articles/306065/20240626/adobe-researchers-develop-new-training-technique-make-ai-less-socially.htm)

For more, see the [media page](/media) — and feel free to **reach out for speaking engagements**.
